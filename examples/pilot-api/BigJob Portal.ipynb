{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# BigJob Portal 1.0\n",
      "\n",
      "Please use the following steps to run BigJob"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'randn' is not defined",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-276ce5d52d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'randn' is not defined"
       ],
       "output_type": "pyerr"
      }
     ],
     "input": [
      "x = randn(10000)\n",
      "hist(x, 100)"
     ],
     "language": "python",
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - Created Pilot Compute Service: redis://localhost:6379/pcs/pcs-4e0f7014-4581-11e2-a016-705681b3df0f\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - start bigjob at: fork://localhost\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - Utilizing Redis Backend\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - Parsing URL: redis://localhost:6379\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - redis:// localhost 6379\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - Connect to Redis: localhost Port: 6379\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - init BigJob w/: redis://localhost:6379\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - initialized BigJob: bigjob:bj-4e17447e-4581-11e2-a016-705681b3df0f\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - create pilot job entry on backend server: bigjob:bj-4e17447e-4581-11e2-a016-705681b3df0f:localhost\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - update state of pilot job to: Unknown stopped: False\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - update description of pilot job to: None\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - set pilot state to: Unknown\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - Use SSH backend\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:43 PM - bigjob - DEBUG - SSH: connect to: localhost\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - BigJob working directory: ssh://localhost/tmp/pilot-compute/bj-4e17447e-4581-11e2-a016-705681b3df0f\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Directory not found: /tmp/pilot-compute/bj-4e17447e-4581-11e2-a016-705681b3df0f\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Create directory at: localhost\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Stage: None to ssh://localhost/tmp/pilot-compute/bj-4e17447e-4581-11e2-a016-705681b3df0f\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - BJ Working Directory: /tmp/pilot-compute/bj-4e17447e-4581-11e2-a016-705681b3df0f\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Adaptor specific modifications: fork\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Escape Bliss\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - \"import sys\n",
        "import os\n",
        "import urllib\n",
        "import sys\n",
        "import time\n",
        "start_time = time.time()\n",
        "home = os.environ.get(\\\"HOME\\\")\n",
        "#print \\\"Home: \\\" + home\n",
        "if home==None: home = os.getcwd()\n",
        "BIGJOB_AGENT_DIR= os.path.join(home, \\\".bigjob\\\")\n",
        "if not os.path.exists(BIGJOB_AGENT_DIR): os.mkdir (BIGJOB_AGENT_DIR)\n",
        "BIGJOB_PYTHON_DIR=BIGJOB_AGENT_DIR+\\\"/python/\\\"\n",
        "if not os.path.exists(BIGJOB_PYTHON_DIR): os.mkdir(BIGJOB_PYTHON_DIR)\n",
        "BOOTSTRAP_URL=\\\"https://raw.github.com/saga-project/BigJob/master/bootstrap/bigjob-bootstrap.py\\\"\n",
        "BOOTSTRAP_FILE=BIGJOB_AGENT_DIR+\\\"/bigjob-bootstrap.py\\\"\n",
        "#ensure that BJ in .bigjob is upfront in sys.path\n",
        "sys.path.insert(0, os.getcwd() + \\\"/../\\\")\n",
        "#sys.path.insert(0, /User/luckow/.bigjob/python/lib\\\")\n",
        "#sys.path.insert(0, os.getcwd() + \\\"/../../\\\")\n",
        "p = list()\n",
        "for i in sys.path:\n",
        "    if i.find(\\\".bigjob/python\\\")>1:\n",
        "          p.insert(0, i)\n",
        "for i in p: sys.path.insert(0, i)\n",
        "print \\\"Python path: \\\" + str(sys.path)\n",
        "print \\\"Python version: \\\" + str(sys.version_info)\n",
        "try: import saga\n",
        "except: print \\\"SAGA and SAGA Python Bindings not found.\\\";\n",
        "try: import bigjob.bigjob_agent\n",
        "except: \n",
        "    print \\\"BigJob not installed. Attempt to install it.\\\"; \n",
        "    opener = urllib.FancyURLopener({}); \n",
        "    opener.retrieve(BOOTSTRAP_URL, BOOTSTRAP_FILE); \n",
        "    print \\\"Execute: \\\" + \\\"python \\\" + BOOTSTRAP_FILE + \\\" \\\" + BIGJOB_PYTHON_DIR\n",
        "    os.system(\\\"/usr/bin/env\\\")\n",
        "    try:\n",
        "        os.system(\\\"python \\\" + BOOTSTRAP_FILE + \\\" \\\" + BIGJOB_PYTHON_DIR); \n",
        "        activate_this = os.path.join(BIGJOB_PYTHON_DIR, \\\"bin/activate_this.py\\\"); \n",
        "        execfile(activate_this, dict(__file__=activate_this))\n",
        "    except:\n",
        "        print \\\"BJ installation failed. Trying system-level python (/usr/bin/python)\\\";\n",
        "        os.system(\\\"/usr/bin/python \\\" + BOOTSTRAP_FILE + \\\" \\\" + BIGJOB_PYTHON_DIR); \n",
        "        activate_this = os.path.join(BIGJOB_PYTHON_DIR, \\\"bin/activate_this.py\\\"); \n",
        "        execfile(activate_this, dict(__file__=activate_this))\n",
        "#try to import BJ once again\n",
        "import bigjob.bigjob_agent\n",
        "# execute bj agent\n",
        "args = list()\n",
        "args.append(\\\"bigjob_agent.py\\\")\n",
        "args.append(\\\"redis://localhost:6379\\\")\n",
        "args.append(\\\"bigjob:bj-4e17447e-4581-11e2-a016-705681b3df0f:localhost\\\")\n",
        "args.append(\\\"PilotComputeServiceQueue-pcs-4e0f7014-4581-11e2-a016-705681b3df0f\\\")\n",
        "print \\\"Bootstrap time: \\\" + str(time.time()-start_time)\n",
        "print \\\"Starting BigJob Agents with following args: \\\" + str(args)\n",
        "bigjob_agent = bigjob.bigjob_agent.bigjob_agent(args)\n",
        "\"\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Working directory: /tmp/pilot-compute/bj-4e17447e-4581-11e2-a016-705681b3df0f\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Creating pilot job with description: {'Executable' : '/usr/bin/env','WorkingDirectory' : '/tmp/pilot-compute/bj-4e17447e-4581-11e2-a016-705681b3df0f','SPMDVariation' : 'single','WallTimeLimit' : '3600','Arguments' : '['python', '-c', '\"import sys\\nimport os\\nimport urllib\\nimport sys\\nimport time\\nstart_time = time.time()\\nhome = os.environ.get(\\\\\"HOME\\\\\")\\n#print \\\\\"Home: \\\\\" + home\\nif home==None: home = os.getcwd()\\nBIGJOB_AGENT_DIR= os.path.join(home, \\\\\".bigjob\\\\\")\\nif not os.path.exists(BIGJOB_AGENT_DIR): os.mkdir (BIGJOB_AGENT_DIR)\\nBIGJOB_PYTHON_DIR=BIGJOB_AGENT_DIR+\\\\\"/python/\\\\\"\\nif not os.path.exists(BIGJOB_PYTHON_DIR): os.mkdir(BIGJOB_PYTHON_DIR)\\nBOOTSTRAP_URL=\\\\\"https://raw.github.com/saga-project/BigJob/master/bootstrap/bigjob-bootstrap.py\\\\\"\\nBOOTSTRAP_FILE=BIGJOB_AGENT_DIR+\\\\\"/bigjob-bootstrap.py\\\\\"\\n#ensure that BJ in .bigjob is upfront in sys.path\\nsys.path.insert(0, os.getcwd() + \\\\\"/../\\\\\")\\n#sys.path.insert(0, /User/luckow/.bigjob/python/lib\\\\\")\\n#sys.path.insert(0, os.getcwd() + \\\\\"/../../\\\\\")\\np = list()\\nfor i in sys.path:\\n    if i.find(\\\\\".bigjob/python\\\\\")>1:\\n          p.insert(0, i)\\nfor i in p: sys.path.insert(0, i)\\nprint \\\\\"Python path: \\\\\" + str(sys.path)\\nprint \\\\\"Python version: \\\\\" + str(sys.version_info)\\ntry: import saga\\nexcept: print \\\\\"SAGA and SAGA Python Bindings not found.\\\\\";\\ntry: import bigjob.bigjob_agent\\nexcept: \\n    print \\\\\"BigJob not installed. Attempt to install it.\\\\\"; \\n    opener = urllib.FancyURLopener({}); \\n    opener.retrieve(BOOTSTRAP_URL, BOOTSTRAP_FILE); \\n    print \\\\\"Execute: \\\\\" + \\\\\"python \\\\\" + BOOTSTRAP_FILE + \\\\\" \\\\\" + BIGJOB_PYTHON_DIR\\n    os.system(\\\\\"/usr/bin/env\\\\\")\\n    try:\\n        os.system(\\\\\"python \\\\\" + BOOTSTRAP_FILE + \\\\\" \\\\\" + BIGJOB_PYTHON_DIR); \\n        activate_this = os.path.join(BIGJOB_PYTHON_DIR, \\\\\"bin/activate_this.py\\\\\"); \\n        execfile(activate_this, dict(__file__=activate_this))\\n    except:\\n        print \\\\\"BJ installation failed. Trying system-level python (/usr/bin/python)\\\\\";\\n        os.system(\\\\\"/usr/bin/python \\\\\" + BOOTSTRAP_FILE + \\\\\" \\\\\" + BIGJOB_PYTHON_DIR); \\n        activate_this = os.path.join(BIGJOB_PYTHON_DIR, \\\\\"bin/activate_this.py\\\\\"); \\n        execfile(activate_this, dict(__file__=activate_this))\\n#try to import BJ once again\\nimport bigjob.bigjob_agent\\n# execute bj agent\\nargs = list()\\nargs.append(\\\\\"bigjob_agent.py\\\\\")\\nargs.append(\\\\\"redis://localhost:6379\\\\\")\\nargs.append(\\\\\"bigjob:bj-4e17447e-4581-11e2-a016-705681b3df0f:localhost\\\\\")\\nargs.append(\\\\\"PilotComputeServiceQueue-pcs-4e0f7014-4581-11e2-a016-705681b3df0f\\\\\")\\nprint \\\\\"Bootstrap time: \\\\\" + str(time.time()-start_time)\\nprint \\\\\"Starting BigJob Agents with following args: \\\\\" + str(args)\\nbigjob_agent = bigjob.bigjob_agent.bigjob_agent(args)\\n\"']','Error' : '/tmp/pilot-compute/bj-4e17447e-4581-11e2-a016-705681b3df0f/stderr-bj-4e17447e-4581-11e2-a016-705681b3df0f-agent.txt','Output' : '/tmp/pilot-compute/bj-4e17447e-4581-11e2-a016-705681b3df0f/stdout-bj-4e17447e-4581-11e2-a016-705681b3df0f-agent.txt','TotalCPUCount' : '1',}\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Submit pilot job to: fork://localhost\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Create PilotCompute for BigJob: bigjob:bj-4e17447e-4581-11e2-a016-705681b3df0f:localhost\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - redis://localhost/bigdata\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - PDS URL: redis://localhost/bigdata:pds-4e95f6c0-4581-11e2-a016-705681b3df0f\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Create PDS directory at redis://localhost/bigdata:pds-4e95f6c0-4581-11e2-a016-705681b3df0f\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - redis://localhost/bigdata\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Use SSH backend\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - SSH: connect to: localhost\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - PilotData Dictionary: {'url': 'redis://localhost/bigdata:pds-4e95f6c0-4581-11e2-a016-705681b3df0f:pd-4e969530-4581-11e2-a016-705681b3df0f', 'pilot_data_description': {'affinity_machine_label': 'mymachine-1', 'service_url': 'ssh://localhost/tmp/pilot-data/', 'affinity_datacenter_label': 'eu-de-south', 'size': 100}, 'id': 'pd-4e969530-4581-11e2-a016-705681b3df0f'}\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Store Redis entry at: redis://localhost/bigdata:pds-4e95f6c0-4581-11e2-a016-705681b3df0f:pd-4e969530-4581-11e2-a016-705681b3df0f:info Content: {\"pilot_data_description\": {\"affinity_machine_label\": \"mymachine-1\", \"service_url\": \"ssh://localhost/tmp/pilot-data/\", \"affinity_datacenter_label\": \"eu-de-south\", \"size\": 100}, \"pilot_data\": {\"url\": \"redis://localhost/bigdata:pds-4e95f6c0-4581-11e2-a016-705681b3df0f:pd-4e969530-4581-11e2-a016-705681b3df0f\", \"pilot_data_description\": {\"affinity_machine_label\": \"mymachine-1\", \"service_url\": \"ssh://localhost/tmp/pilot-data/\", \"affinity_datacenter_label\": \"eu-de-south\", \"size\": 100}, \"id\": \"pd-4e969530-4581-11e2-a016-705681b3df0f\"}, \"data_unit_urls\": null, \"security_context\": null}\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - redis://localhost/bigjob\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - CDS URL: redis://localhost/bigjob:cds-4eccfa9e-4581-11e2-a016-705681b3df0f\n"
       ]
      },
      {
       "stream": "stderr",
       "output_type": "stream",
       "text": [
        "12/13/2012 07:00:44 PM - bigjob - DEBUG - Create CDS directory at redis://localhost/bigjob:cds-4eccfa9e-4581-11e2-a016-705681b3df0f\n"
       ]
      }
     ],
     "input": [
      "import bigjob\n",
      "from pilot import PilotComputeService, PilotDataService, ComputeDataService, State\n",
      "\n",
      "COORDINATION_URL = \"redis://localhost:6379\"\n",
      "\n",
      "if __name__ == \"__main__\":      \n",
      "    \n",
      "    pilot_compute_service = PilotComputeService(coordination_url=COORDINATION_URL)\n",
      "\n",
      "    # create pilot job service and initiate a pilot job\n",
      "    pilot_compute_description = {\n",
      "                             \"service_url\": 'fork://localhost',\n",
      "                             \"number_of_processes\": 1,                             \n",
      "                             \"working_directory\": \"/tmp/pilot-compute/\",\n",
      "                             'affinity_datacenter_label': \"eu-de-south\",              \n",
      "                             'affinity_machine_label': \"mymachine-1\" \n",
      "                            }\n",
      "    \n",
      "    pilot_compute_service.create_pilot(pilot_compute_description=pilot_compute_description)\n",
      "    \n",
      "    \n",
      "    # create pilot data service (factory for data pilots (physical, distributed storage))\n",
      "    # and pilot data\n",
      "    pilot_data_service = PilotDataService(coordination_url=COORDINATION_URL)\n",
      "    pilot_data_description={\n",
      "                                \"service_url\": \"ssh://localhost/tmp/pilot-data/\",\n",
      "                                \"size\": 100,   \n",
      "                                \"affinity_datacenter_label\": \"eu-de-south\",              \n",
      "                                \"affinity_machine_label\": \"mymachine-1\"                              \n",
      "                             }\n",
      "    \n",
      "    pilot_data_service.create_pilot(pilot_data_description=pilot_data_description)\n",
      "     \n",
      "    compute_data_service = ComputeDataService()\n",
      "    compute_data_service.add_pilot_compute_service(pilot_compute_service)\n",
      "    compute_data_service.add_pilot_data_service(pilot_data_service)"
     ],
     "language": "python",
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# Create Data Unit Description\n",
      "    #base_dir = \"../data1\"\n",
      "    #url_list = os.listdir(base_dir)\n",
      "    # make absolute paths\n",
      "    #absolute_url_list = [os.path.join(base_dir, i) for i in url_list]\n",
      "    data_unit_description = {\n",
      "                              \"file_urls\": [os.path.join(os.getcwd(), \"../test.txt\")],\n",
      "                              \"affinity_datacenter_label\": \"eu-de-south\",              \n",
      "                              \"affinity_machine_label\": \"mymachine-1\"\n",
      "                             }    \n",
      "      \n",
      "    \n",
      "    # submit pilot data to a pilot store    \n",
      "    data_unit = compute_data_service.submit_data_unit(data_unit_description)\n",
      "    logging.debug(\"Submitted Data Unit: \" + data_unit.get_url())\n",
      "    logging.debug(\"Pilot Data URL: %s Description: \\n%s\"%(data_unit, str(pilot_data_description)))"
     ],
     "language": "python"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Submit compute unit"
     ]
    },
    {
     "cell_type": "code",
     "execution_count": null,
     "metadata": {},
     "outputs": [],
     "input": [
      "# start compute unit\n",
      "    compute_unit_description = {\n",
      "            \"executable\": \"/bin/cat\",\n",
      "            \"arguments\": [\"test.txt\"],\n",
      "            \"number_of_processes\": 1,\n",
      "            \"output\": \"stdout.txt\",\n",
      "            \"error\": \"stderr.txt\",   \n",
      "            \"input_data\" : [data_unit.get_url()], # this stages the content of the data unit to the working directory of the compute unit\n",
      "            \"output_data\": [\n",
      "                            {\n",
      "                             data_unit.get_url(): \n",
      "                             [\"std*\"]\n",
      "                            }\n",
      "                           ],  \n",
      "            \"affinity_datacenter_label\": \"eu-de-south\",              \n",
      "            \"affinity_machine_label\": \"mymachine-1\" \n",
      "    }    \n",
      "    \n",
      "    \n",
      "    \n",
      "    compute_unit = compute_data_service.submit_compute_unit(compute_unit_description)\n",
      "    logging.debug(\"Finished setup of PSS and PDS. Waiting for scheduling of PD\")\n",
      "    compute_data_service.wait()\n",
      "    \n",
      "    data_unit.export(\"/tmp/output\")\n",
      "    logging.debug(\"Terminate Pilot Compute/Data Service\")\n",
      "    compute_data_service.cancel()\n",
      "    pilot_data_service.cancel()\n",
      "    pilot_compute_service.cancel()"
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {
  "name": "BigJob Portal"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}